#!/usr/bin/env python3
from dotenv import load_dotenv

# Load default environment variables (.env)
load_dotenv()

import os
import logging

from typing import Dict, List
import chromadb
import tiktoken as tiktoken

# from chromadb.api.types import Documents, EmbeddingFunction, Embeddings
import re
from baby_agi import BabyAGI

# default opt out of chromadb telemetry.
from chromadb.config import Settings

def make_baby(coop_mode: str = "none", join_existing: bool = False):
    agent_settings = {}
    agent_settings["vectordb_client"] = chromadb.Client(
        Settings(anonymized_telemetry=False)
    )
    agent_settings["LLM_MODEL"] = os.getenv("LLM_MODEL", "").lower()
    agent_settings["LLAMA_API_PATH"] = os.getenv("LLAMA_API_PATH", "")
    agent_settings["RESULTS_STORE_NAME"] = os.getenv("RESULTS_STORE_NAME", "")
    agent_settings["AGENT_NAME"].AGENT_NAME = os.getenv("AGENT_NAME", "")
    agent_settings["OBJECTIVE"] = os.getenv("OBJECTIVE", "")
    agent_settings["INITIAL_TASK"] = os.getenv("INITIAL_TASK", "")

    if not baby_agi.JOIN_EXISTING_OBJECTIVE:
        print(
            "\033[93m\033[1m"
            + "\nInitial task:"
            + "\033[0m\033[0m"
            + f" {baby_agi.INITIAL_TASK}"
        )
    else:
        print("\033[93m\033[1m" + f"\nJoining to help the objective" + "\033[0m\033[0m")

    return baby_agi


# Llama embedding function
# class LlamaEmbeddingFunction(EmbeddingFunction):
#     def __init__(self):
#         return

#     def __call__(self, texts: Documents) -> Embeddings:
#         embeddings = []
#         for t in texts:
#             e = llm_embed.embed(t)
#             embeddings.append(e)
#         return embeddings


# Results storage using local ChromaDB
class DefaultResultsStorage:
    def __init__(self, RESULTS_STORE_NAME: str = ""):
        logging.getLogger("chromadb").setLevel(logging.ERROR)
        # Create Chroma collection
        chroma_persist_dir = "chroma"
        chroma_client = chromadb.PersistentClient(
            settings=chromadb.config.Settings(
                persist_directory=chroma_persist_dir,
            )
        )

        metric = "cosine"

        embedding_function = LlamaEmbeddingFunction()

        self.collection = chroma_client.get_or_create_collection(
            name=RESULTS_STORE_NAME,
            metadata={"hnsw:space": metric},
            embedding_function=embedding_function,
        )

    def add(self, task: Dict, result: str, result_id: str):
        embeddings = llm_embed.embed(result)
        if (
            len(self.collection.get(ids=[result_id], include=[])["ids"]) > 0
        ):  # Check if the result already exists
            return self.collection.update(
                ids=result_id,
                embeddings=embeddings,
                documents=result,
                metadatas={"task": task["task_name"], "result": result},
            )

        return self.collection.add(
            ids=result_id,
            embeddings=embeddings,
            documents=result,
            metadatas={"task": task["task_name"], "result": result},
        )

    def query(self, query: str, top_results_num: int) -> List[dict]:
        count: int = self.collection.count()
        if count == 0:
            return []
        results = self.collection.query(
            query_texts=query,
            n_results=min(top_results_num, count),
            include=["metadatas"],
        )
        return [item["task"] for item in results["metadatas"][0]]






# Initialize tasks storage
tasks_storage = SingleTaskListStorage()


def prioritization_agent():
    task_names = tasks_storage.get_task_names()
    bullet_string = "\n"

    prompt = f""""""

    print(f"\n****TASK PRIORITIZATION AGENT PROMPT****\n{prompt}\n")
    response = openai_call(prompt, max_tokens=2000)
    print(f"\n****TASK PRIORITIZATION AGENT RESPONSE****\n{response}\n")
    if not response:
        print(
            "Received empty response from prioritization agent. Keeping task list unchanged."
        )
        return
    new_tasks = response.split("\n") if "\n" in response else [response]
    new_tasks_list = []
    for task_string in new_tasks:
        task_parts = task_string.strip().split(".", 1)
        if len(task_parts) == 2:
            task_id = "".join(s for s in task_parts[0] if s.isnumeric())
            task_name = re.sub(r"[^\w\s_]+", "", task_parts[1]).strip()
            if task_name.strip():
                new_tasks_list.append({"task_id": task_id, "task_name": task_name})

    return new_tasks_list


# Execute a task based on the objective and five previous tasks
def execution_agent(objective: str, task: str) -> str:
    """
    Executes a task based on the given objective and previous context.

    Args:
        objective (str): The objective or goal for the AI to perform the task.
        task (str): The task to be executed by the AI.

    Returns:
        str: The response generated by the AI for the given task.

    """

    context = context_agent(query=objective, top_results_num=5)
    # print("\n****RELEVANT CONTEXT****\n")
    # print(context)
    # print('')
    prompt = f"Perform one task based on the following objective: {objective}.\n"
    if context:
        prompt += "Take into account these previously completed tasks:" + "\n".join(
            context
        )
    prompt += f"\nYour task: {task}\nResponse:"
    return openai_call(prompt, max_tokens=2000)


# Get the top n completed tasks for the objective
def context_agent(query: str, top_results_num: int):
    """
    Retrieves context for a given query from an index of tasks.

    Args:
        query (str): The query or objective for retrieving context.
        top_results_num (int): The number of top results to retrieve.

    Returns:
        list: A list of tasks as context for the given query, sorted by relevance.

    """
    results = results_storage.query(query=query, top_results_num=top_results_num)
    # print("****RESULTS****")
    # print(results)
    return results


def main():
    loop = True

    initial_task = {"task_id": tasks_storage.next_task_id(), "task_name": INITIAL_TASK}
    tasks_storage.append(initial_task)

    while loop:
        # As long as there are tasks in the storage...
        if not tasks_storage.is_empty():
            # Print the task list
            print("\033[95m\033[1m" + "\n*****TASK LIST*****\n" + "\033[0m\033[0m")
            for t in tasks_storage.get_task_names():
                print(" â€¢ " + str(t))

            # Step 1: Pull the first incomplete task
            task = tasks_storage.popleft()
            print("\033[92m\033[1m" + "\n*****NEXT TASK*****\n" + "\033[0m\033[0m")
            print(str(task["task_name"]))

            # Send to execution function to complete the task based on the context
            result = execution_agent(OBJECTIVE, str(task["task_name"]))
            print("\033[93m\033[1m" + "\n*****TASK RESULT*****\n" + "\033[0m\033[0m")
            print(result)

            # Step 2: Enrich result and store in the results storage
            # This is where you should enrich the result if needed
            enriched_result = {"data": result}
            # extract the actual result from the dictionary
            # since we don't do enrichment currently
            # vector = enriched_result["data"]

            result_id = f"result_{task['task_id']}"

            results_storage.add(task, result, result_id)

            # Step 3: Create new tasks and re-prioritize task list
            # only the main instance in cooperative mode does that
            new_tasks = task_creation_agent(
                OBJECTIVE,
                enriched_result,
                task["task_name"],
                tasks_storage.get_task_names(),
            )

            print("Adding new tasks to task_storage")
            for new_task in new_tasks:
                new_task.update({"task_id": tasks_storage.next_task_id()})
                print(str(new_task))
                tasks_storage.append(new_task)

            prioritized_tasks = prioritization_agent()
            if prioritized_tasks:
                tasks_storage.replace(prioritized_tasks)

        else:
            print("Done.")
            loop = False


if __name__ == "__main__":
    main()
